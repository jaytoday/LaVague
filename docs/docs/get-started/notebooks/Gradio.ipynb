{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Gradio Demo\n",
        "\n",
        "### Installation"
      ],
      "metadata": {
        "id": "RPQxVCQGWbF9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxPdG0EkqlYM",
        "outputId": "af12933f-8b5d-465f-bb61-197d3d70d97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lavague\n",
            "  Downloading lavague-1.1.1.post2-py3-none-any.whl (8.3 kB)\n",
            "Collecting lavague-gradio\n",
            "  Downloading lavague_gradio-0.2.1-py3-none-any.whl (3.6 kB)\n",
            "Collecting lavague-contexts-openai<0.3.0,>=0.2.0 (from lavague)\n",
            "  Downloading lavague_contexts_openai-0.2.0-py3-none-any.whl (2.4 kB)\n",
            "Collecting lavague-core<0.3.0,>=0.2.8 (from lavague)\n",
            "  Downloading lavague_core-0.2.10-py3-none-any.whl (33 kB)\n",
            "Collecting lavague-drivers-selenium<0.3.0,>=0.2.2 (from lavague)\n",
            "  Downloading lavague_drivers_selenium-0.2.2.post2-py3-none-any.whl (6.9 kB)\n",
            "Collecting gradio==4.26.0 (from lavague-gradio)\n",
            "  Downloading gradio-4.26.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.15.1 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading gradio_client-0.15.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (2.7.3)\n",
            "Collecting pydub (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (0.9.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.26.0->lavague-gradio) (4.12.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.15.1->gradio==4.26.0->lavague-gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.15.1->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.9 (from lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading llama_index_embeddings_openai-0.1.10-py3-none-any.whl (6.2 kB)\n",
            "Collecting llama-index-llms-azure-openai<0.2.0,>=0.1.8 (from lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading llama_index_llms_azure_openai-0.1.8-py3-none-any.whl (4.9 kB)\n",
            "Collecting llama-index-llms-openai<0.2.0,>=0.1.9 (from lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading llama_index_llms_openai-0.1.22-py3-none-any.whl (11 kB)\n",
            "Collecting llama-index-multi-modal-llms-azure-openai<0.2.0,>=0.1.4 (from lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading llama_index_multi_modal_llms_azure_openai-0.1.4-py3-none-any.whl (3.7 kB)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.6 (from lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.6-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: ipython<8.0.0,>=7.34.0 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.8->lavague) (7.34.0)\n",
            "Collecting langchain<0.2.0,>=0.1.20 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index<0.11.0,>=0.10.19 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index-0.10.43-py3-none-any.whl (6.8 kB)\n",
            "Collecting llama-index-retrievers-bm25<0.2.0,>=0.1.3 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_retrievers_bm25-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting lxml<6.0.0,>=5.1.1 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml-html-clean<0.2.0,>=0.1.1 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading lxml_html_clean-0.1.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from lavague-core<0.3.0,>=0.2.8->lavague) (1.0.8)\n",
            "Collecting trafilatura<2.0.0,>=1.9.0 (from lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading trafilatura-1.10.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting selenium<5.0.0,>=4.18.1 (from lavague-drivers-selenium<0.3.0,>=0.2.2->lavague)\n",
            "  Downloading selenium-4.21.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.26.0->lavague-gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.26.0->lavague-gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.26.0->lavague-gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==4.26.0->lavague-gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.26.0->lavague-gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.26.0->lavague-gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.26.0->lavague-gradio) (4.66.4)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (3.0.45)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (4.9.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.38 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading langsmith-0.1.74-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.8/124.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (8.3.0)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_agent_openai-0.2.7-py3-none-any.whl (12 kB)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_cli-0.1.12-py3-none-any.whl (26 kB)\n",
            "Collecting llama-index-core==0.10.43 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_core-0.10.43-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_program_openai-0.1.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
            "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (3.8.1)\n",
            "Collecting openai>=1.1.0 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading openai-1.31.2-py3-none-any.whl (324 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken>=0.3.3 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (1.14.1)\n",
            "Collecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading azure_identity-1.16.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.1/166.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rank-bm25<0.3.0,>=0.2.2 (from llama-index-retrievers-bm25<0.2.0,>=0.1.3->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.26.0->lavague-gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==4.26.0->lavague-gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.26.0->lavague-gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio==4.26.0->lavague-gradio) (2.18.4)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Collecting courlan>=1.1.0 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading courlan-1.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting htmldate>=1.8.1 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading htmldate-1.8.1-py3-none-any.whl (31 kB)\n",
            "Collecting justext>=3.0.1 (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading jusText-3.0.1-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague) (3.3.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (1.9.4)\n",
            "Collecting azure-core>=1.23.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.10/dist-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague) (42.0.7)\n",
            "Collecting msal>=1.24.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading msal-1.28.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal-extensions>=0.3.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: babel>=2.11.0 in /usr/local/lib/python3.10/dist-packages (from courlan>=1.1.0->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague) (2.15.0)\n",
            "Collecting tld>=0.13 (from courlan>=1.1.0->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading tld-0.13-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio==4.26.0->lavague-gradio)\n",
            "  Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
            "  Downloading fastapi_cli-0.0.2-py3-none-any.whl (9.1 kB)\n",
            "Collecting fastapi (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dateparser>=1.1.2 (from htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading dateparser-1.2.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.8.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.26.0->lavague-gradio) (0.18.1)\n",
            "Requirement already satisfied: lxml[html_clean]>=4.4.2 in /usr/local/lib/python3.10/dist-packages (from justext>=3.0.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague) (4.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging (from gradio==4.26.0->lavague-gradio)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (4.12.3)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Collecting llama-parse<0.5.0,>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading llama_parse-0.4.4-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0.0,>=7.34.0->lavague-core<0.3.0,>=0.2.8->lavague) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.26.0->lavague-gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio) (3.0.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague) (3.0.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio==4.26.0->lavague-gradio) (1.2.1)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague) (2.4.0)\n",
            "Collecting outcome (from trio~=0.17->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium<5.0.0,>=4.18.1->lavague-drivers-selenium<0.3.0,>=0.2.2->lavague) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (2.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague) (1.16.0)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague) (2024.5.15)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser>=1.1.2->htmldate>=1.8.1->trafilatura<2.0.0,>=1.9.0->lavague-core<0.3.0,>=0.2.8->lavague) (5.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.20->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "\u001b[33mWARNING: lxml 4.9.4 does not provide the extra 'html_clean'\u001b[0m\u001b[33m\n",
            "\u001b[0mINFO: pip is looking at multiple versions of lxml[html-clean] to determine which version is compatible with other requirements. This could take a while.\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.26.0->lavague-gradio) (0.1.2)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague) (2.3.0)\n",
            "Collecting portalocker<3,>=1.0 (from msal-extensions>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (1.4.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague) (1.7.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core==0.10.43->llama-index<0.11.0,>=0.10.19->lavague-core<0.3.0,>=0.2.8->lavague)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.8->lavague-contexts-openai<0.3.0,>=0.2.0->lavague) (2.22)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=aeeef58f0bfb45ce65828d53866e669d71db34466d636ecafc3951bc28468077\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: striprtf, pydub, ffmpy, dirtyjson, websockets, tomlkit, tld, shellingham, semantic-version, ruff, rank-bm25, python-multipart, pypdf, portalocker, packaging, outcome, orjson, mypy-extensions, lxml, jsonpointer, jedi, h11, deprecated, colorama, aiofiles, wsproto, uvicorn, typing-inspect, trio, tiktoken, starlette, marshmallow, lxml-html-clean, jsonpatch, httpcore, dateparser, courlan, azure-core, trio-websocket, langsmith, httpx, htmldate, fastapi, dataclasses-json, selenium, openai, msal, llamaindex-py-client, langchain-core, justext, gradio-client, trafilatura, msal-extensions, llama-index-legacy, llama-index-core, langchain-text-splitters, langchain-community, gradio, llama-parse, llama-index-retrievers-bm25, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, langchain, azure-identity, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-azure-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-multi-modal-llms-azure-openai, llama-index-question-gen-openai, llama-index, lavague-core, lavague-gradio, lavague-drivers-selenium, lavague-contexts-openai, lavague\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.9.4\n",
            "    Uninstalling lxml-4.9.4:\n",
            "      Successfully uninstalled lxml-4.9.4\n",
            "Successfully installed aiofiles-23.2.1 azure-core-1.30.1 azure-identity-1.16.0 colorama-0.4.6 courlan-1.2.0 dataclasses-json-0.6.6 dateparser-1.2.0 deprecated-1.2.14 dirtyjson-1.0.8 fastapi-0.110.3 ffmpy-0.3.2 gradio-4.26.0 gradio-client-0.15.1 h11-0.14.0 htmldate-1.8.1 httpcore-1.0.5 httpx-0.27.0 jedi-0.19.1 jsonpatch-1.33 jsonpointer-2.4 justext-3.0.1 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-text-splitters-0.0.2 langsmith-0.1.74 lavague-1.1.1.post2 lavague-contexts-openai-0.2.0 lavague-core-0.2.10 lavague-drivers-selenium-0.2.2.post2 lavague-gradio-0.2.1 llama-index-0.10.43 llama-index-agent-openai-0.2.7 llama-index-cli-0.1.12 llama-index-core-0.10.43 llama-index-embeddings-openai-0.1.10 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48 llama-index-llms-azure-openai-0.1.8 llama-index-llms-openai-0.1.22 llama-index-multi-modal-llms-azure-openai-0.1.4 llama-index-multi-modal-llms-openai-0.1.6 llama-index-program-openai-0.1.6 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.23 llama-index-readers-llama-parse-0.1.4 llama-index-retrievers-bm25-0.1.3 llama-parse-0.4.4 llamaindex-py-client-0.1.19 lxml-5.2.2 lxml-html-clean-0.1.1 marshmallow-3.21.3 msal-1.28.0 msal-extensions-1.1.0 mypy-extensions-1.0.0 openai-1.31.2 orjson-3.10.3 outcome-1.3.0.post0 packaging-23.2 portalocker-2.8.2 pydub-0.25.1 pypdf-4.2.0 python-multipart-0.0.9 rank-bm25-0.2.2 ruff-0.4.8 selenium-4.21.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 striprtf-0.0.26 tiktoken-0.7.0 tld-0.13 tomlkit-0.12.0 trafilatura-1.10.0 trio-0.25.1 trio-websocket-0.11.1 typing-inspect-0.9.0 uvicorn-0.30.1 websockets-11.0.3 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install lavague lavague-gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check if running in Google Colab\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "else:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "oq2zHbfYXXbo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### launch Gradio demo"
      ],
      "metadata": {
        "id": "QLaAsqXzWgWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lavague.drivers.selenium import SeleniumDriver\n",
        "from lavague.core import ActionEngine, WorldModel\n",
        "from lavague.core.agents import WebAgent\n",
        "\n",
        "selenium_driver = SeleniumDriver(headless=True)\n",
        "action_engine = ActionEngine(selenium_driver)\n",
        "world_model = WorldModel()\n",
        "agent = WebAgent(world_model, action_engine)\n",
        "\n",
        "# Set our URL\n",
        "agent.get(\"https://huggingface.co/docs\")\n",
        "\n",
        "# Launch our demo with our objective\n",
        "agent.demo(\"Go on the quicktour of PEFT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "IgXVnJ5MWab5",
        "outputId": "7de0447f-200d-4dad-cb3c-7a081126eed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-06-06 16:24:42,545 - INFO - Screenshot folder cleared\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IMPORTANT: You are using gradio version 4.26.0, however version 4.29.0 is available, please upgrade.\n",
            "--------\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://975f0c5605f7311f76.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://975f0c5605f7311f76.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}